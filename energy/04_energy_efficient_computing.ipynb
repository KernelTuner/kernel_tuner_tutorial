{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Tuner Tutorial - Energy aware computing\n",
    "\n",
    "## Hands-on\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "We start by downloading and installing the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for non-cached:\n",
    "#%pip install pycuda\n",
    "#%pip install pyopencl\n",
    "#%pip install cupy\n",
    "#%pip install pynvml\n",
    "\n",
    "%pip install matplotlib\n",
    "%pip install seaborn~=0.13.0\n",
    "%pip install pandas\n",
    "%pip install git+https://github.com/KernelTuner/kernel_tuner.git@master\n",
    "\n",
    "!wget -O GEMM_A100_cache.json.bz2 https://github.com/KernelTuner/kernel_tuner_tutorial/blob/master/energy/data/GEMM_NVML_NVIDIA_A100-PCIE-40GB_freq_cache_fake_timings.json.bz2?raw=true\n",
    "!bunzip2 GEMM_A100_cache.json.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the required packages and set our defaults for plotting with Seaborn and Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kernel_tuner as kt\n",
    "from copy import deepcopy\n",
    "\n",
    "# only for non-cached:\n",
    "# from kernel_tuner.observers.nvml import NVMLObserver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "sns.set_context(\"paper\", rc={\"font.size\":10,\"axes.titlesize\":9,\"axes.labelsize\":12})  \n",
    "sns.set(font_scale = 1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Setup\n",
    "\n",
    "We start the tuning setup by defining the metrics we will use to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of operations that the matrix multiply performs\n",
    "def ops(m, n, k):\n",
    "    return (m * n * k * 2 + 2 * m * k) / 1e9\n",
    "\n",
    "# Size of the matrices\n",
    "m = n = k = 4096\n",
    "problem_size = (512, 512)\n",
    "total_flops = ops(m, n, k)\n",
    "\n",
    "metrics = dict()\n",
    "# Throughput\n",
    "metrics[\"GFLOP/s\"] = lambda p: total_flops / (p[\"time\"] / 1000.0)\n",
    "# Energy efficiency\n",
    "metrics[\"GFLOPS/W\"] = lambda p: total_flops / p[\"nvml_energy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the parameters we would like to tune, their possible values, and restrictions that apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunable parameters\n",
    "tune_params = dict()\n",
    "# The nvml_gr_clock is the tunable parameter affecting the GPU frequency in MHz, 690 is closest to the baseclock of 765\n",
    "tune_params[\"nvml_gr_clock\"] = [330, 510, 690, 870, 1050, 1230, 1410]\n",
    "\n",
    "tune_params[\"MWG\"] = [16, 32, 64, 128]\n",
    "tune_params[\"NWG\"] = [16, 32, 64, 128]\n",
    "tune_params[\"KWG\"] = [32]\n",
    "tune_params[\"MDIMC\"] = [8, 16, 32]\n",
    "tune_params[\"NDIMC\"] = [8, 16, 32]\n",
    "tune_params[\"MDIMA\"] = [8, 16, 32]\n",
    "tune_params[\"NDIMB\"] = [8, 16, 32]\n",
    "tune_params[\"KWI\"] = [2]\n",
    "tune_params[\"VWM\"] = [1, 2, 4, 8]\n",
    "tune_params[\"VWN\"] = [1, 2, 4, 8]\n",
    "tune_params[\"STRM\"] = [0]\n",
    "tune_params[\"STRN\"] = [0]\n",
    "tune_params[\"SA\"] = [0, 1]\n",
    "tune_params[\"SB\"] = [0, 1]\n",
    "tune_params[\"PRECISION\"] = [32]\n",
    "\n",
    "# Grid size\n",
    "grid_div_x = [\"MWG\"]\n",
    "grid_div_y = [\"NWG\"]\n",
    "block_size_names = [\"MDIMC\", \"NDIMC\", \"block_size_z\"]\n",
    "\n",
    "# Search space restriction\n",
    "restrict = []\n",
    "restrict += [\"KWG % KWI == 0\"]\n",
    "restrict += [\"MWG % (MDIMC * VWM) == 0\"]\n",
    "restrict += [\"NWG % (NDIMC * VWN) == 0\"]\n",
    "restrict += [\"MWG % (MDIMA * VWM) == 0\"]\n",
    "restrict += [\"NWG % (NDIMB * VWN) == 0\"]\n",
    "restrict += [\"KWG % ((MDIMC * NDIMC)/MDIMA) == 0\"]\n",
    "restrict += [\"KWG % ((MDIMC * NDIMC)/NDIMB) == 0\"]\n",
    "restrict += [\"not (MWG == 128 and NWG == 128 and MDIMC == 8 and NDIMC == 8)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we setup a Pandas dataframe to keep track of the configurations. \n",
    "This is just some boilerplate to easily print and plot configurations later, so feel free to execute the cell without looking into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from warnings import warn\n",
    "\n",
    "df = None\n",
    "\n",
    "def add_to_dataframe(name: str, config: dict):\n",
    "    global df\n",
    "    new_config = dict()\n",
    "    new_config[\"name\"] = name\n",
    "    # throw out any data that doesn't play nicely in a Pandas dataframe\n",
    "    for key, value in config.items():\n",
    "        if not isinstance(value, (list, tuple)):\n",
    "            new_config[key] = value\n",
    "    # if the name already exists, overwrite its values\n",
    "    if df is not None and (df['name'].eq(name)).any():\n",
    "        warn(f\"{name} was already in dataframe, overwriting values\")\n",
    "        index = df.index[df.name == name]\n",
    "        df.loc[index, list(new_config.keys())] = list(new_config.values())\n",
    "        return\n",
    "    # encapsulate each value as a list\n",
    "    for key, value in config.items():\n",
    "        new_config[key] = [value]\n",
    "    # create dataframe\n",
    "    df_add = pd.DataFrame(new_config)\n",
    "    # if there is no dataframe, create one\n",
    "    if df is None:\n",
    "        df = df_add\n",
    "        return\n",
    "    # if not, add it to the existing dataframe\n",
    "    df = pd.concat([df, df_add], ignore_index=True, sort=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make a simple function for getting the best configuration from a kernel tuner run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_config(objective: str, tune_parameters: dict, higher_is_better=True) -> dict:\n",
    "    _, env_opt = kt.tune_kernel(\n",
    "        \"Xgemm\",\n",
    "        \"\",\n",
    "        problem_size,\n",
    "        [],\n",
    "        tune_parameters,\n",
    "        block_size_names=deepcopy(block_size_names),\n",
    "        simulation_mode=True,\n",
    "        restrictions=restrict,\n",
    "        grid_div_x=grid_div_x,\n",
    "        grid_div_y=grid_div_y,\n",
    "        strategy=\"brute_force\",\n",
    "        metrics=metrics,\n",
    "        objective=objective,\n",
    "        objective_higher_is_better=higher_is_better,\n",
    "        cache=\"GEMM_A100_cache.json\",\n",
    "        quiet=True\n",
    "    )\n",
    "    return env_opt['best_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Time\n",
    "\n",
    "We start by simply optimizing for the lowest possible time, and printing the result and the energy it takes in Joule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_race_to_idle_all_clocks = get_optimal_config(\"time\", tune_params, higher_is_better=False)\n",
    "add_to_dataframe(\"race-to-idle (global)\", config_race_to_idle_all_clocks)\n",
    "df[['name', 'time', 'nvml_energy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Time and Energy\n",
    "\n",
    "The next step is to use our previous time-optimal configuration, and re-tune only the clock frequencies for energy efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_second_phase(baseconfig: dict, tune_key: str, objective: str, higher_is_better=True):\n",
    "    tune_params_config = deepcopy(tune_params)\n",
    "    for key, value in baseconfig.items():\n",
    "        if key != tune_key and key in tune_params_config:\n",
    "            tune_params_config[key] = [value]\n",
    "    return get_optimal_config(objective, tune_params_config, higher_is_better)\n",
    "\n",
    "config_race_to_idle_plus_clocks = tune_second_phase(config_race_to_idle_all_clocks, tune_key='nvml_gr_clock', objective='GFLOPS/W')\n",
    "add_to_dataframe(\"race-to-idle + clocks\", config_race_to_idle_plus_clocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Energy\n",
    "\n",
    "The final step is to tune for energy efficiency globally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_energy_to_solution_global = get_optimal_config(\"GFLOPS/W\", tune_params)\n",
    "add_to_dataframe(\"energy-to-solution (global)\", config_energy_to_solution_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Results\n",
    "\n",
    "We can now look at the results in terms of energy efficiency per configuration in the bar chart below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=df.name, x=df.nvml_energy, orient='h', hue=df.name, legend=False)\n",
    "plt.xlabel('Energy (J), lower is better')\n",
    "plt.ylabel('')\n",
    "plt.title('Lowest energy configuration')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also make a scatterplot to show the relation between energy and time of our three configurations. \n",
    "The performance-optimized configuration gives the best performance, but at the cost of almost double the energy of the energy-optimized configuration.\n",
    "The second configuration provides middle ground, being slower in time, but more energy efficient than global race-to-idle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=df.time, x=df.nvml_energy, hue=df.name, s=250)\n",
    "plt.xlabel('Energy (J), lower is better')\n",
    "plt.ylabel('Time, lower is better')\n",
    "plt.title('Energy versus time')\n",
    "plt.legend(title='')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerneltuner_bayesopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
