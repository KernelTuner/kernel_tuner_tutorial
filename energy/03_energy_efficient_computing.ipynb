{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Tuner Tutorial - Energy aware computing\n",
    "\n",
    "## Hands-on\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "We start by downloading and installing the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kernel-tuner[tutorial]==1.0.0b4\n",
    "%pip install seaborn~=0.13.0\n",
    "\n",
    "!wget -O GEMM_A100_cache.json.bz2 https://github.com/KernelTuner/kernel_tuner_tutorial/blob/master/energy/data/GEMM_NVML_NVIDIA_A100-PCIE-40GB_freq_cache_fake_timings.json.bz2?raw=true\n",
    "!bunzip2 GEMM_A100_cache.json.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the required packages and set our defaults for plotting with Seaborn and Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kernel_tuner as kt\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "sns.set_context(\"paper\", rc={\"font.size\":10,\"axes.titlesize\":9,\"axes.labelsize\":12})  \n",
    "sns.set(font_scale = 1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Setup\n",
    "\n",
    "We start the tuning setup by defining the metrics we will use to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of operations that the matrix multiply performs\n",
    "def ops(m, n, k):\n",
    "    return (m * n * k * 2 + 2 * m * k) / 1e9\n",
    "\n",
    "# Size of the matrices\n",
    "m = n = k = 4096\n",
    "problem_size = (512, 512)\n",
    "total_flops = ops(m, n, k)\n",
    "\n",
    "metrics = dict()\n",
    "# Throughput\n",
    "metrics[\"GFLOP/s\"] = lambda p: total_flops / (p[\"time\"] / 1000.0)\n",
    "# Energy efficiency\n",
    "metrics[\"GFLOPS/W\"] = lambda p: total_flops / p[\"nvml_energy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the parameters we would like to tune, their possible values, and restrictions that apply, creating the space of possible configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunable parameters\n",
    "tune_params = dict()\n",
    "# The nvml_gr_clock is the tunable parameter affecting the GPU frequency in MHz, 690 is closest to the baseclock of 765\n",
    "tune_params[\"nvml_gr_clock\"] = [330, 510, 690, 870, 1050, 1230, 1410]\n",
    "\n",
    "tune_params[\"MWG\"] = [16, 32, 64, 128]\n",
    "tune_params[\"NWG\"] = [16, 32, 64, 128]\n",
    "tune_params[\"KWG\"] = [32]\n",
    "tune_params[\"MDIMC\"] = [8, 16, 32]\n",
    "tune_params[\"NDIMC\"] = [8, 16, 32]\n",
    "tune_params[\"MDIMA\"] = [8, 16, 32]\n",
    "tune_params[\"NDIMB\"] = [8, 16, 32]\n",
    "tune_params[\"KWI\"] = [2]\n",
    "tune_params[\"VWM\"] = [1, 2, 4, 8]\n",
    "tune_params[\"VWN\"] = [1, 2, 4, 8]\n",
    "tune_params[\"STRM\"] = [0]\n",
    "tune_params[\"STRN\"] = [0]\n",
    "tune_params[\"SA\"] = [0, 1]\n",
    "tune_params[\"SB\"] = [0, 1]\n",
    "tune_params[\"PRECISION\"] = [32]\n",
    "\n",
    "# Grid size\n",
    "grid_div_x = [\"MWG\"]\n",
    "grid_div_y = [\"NWG\"]\n",
    "block_size_names = [\"MDIMC\", \"NDIMC\"]\n",
    "\n",
    "# Search space restriction\n",
    "restrict = []\n",
    "restrict += [\"KWG % KWI == 0\"]\n",
    "restrict += [\"MWG % (MDIMC * VWM) == 0\"]\n",
    "restrict += [\"NWG % (NDIMC * VWN) == 0\"]\n",
    "restrict += [\"MWG % (MDIMA * VWM) == 0\"]\n",
    "restrict += [\"NWG % (NDIMB * VWN) == 0\"]\n",
    "restrict += [\"KWG % ((MDIMC * NDIMC)/MDIMA) == 0\"]\n",
    "restrict += [\"KWG % ((MDIMC * NDIMC)/NDIMB) == 0\"]\n",
    "restrict += [\"not (MWG == 128 and NWG == 128 and MDIMC == 8 and NDIMC == 8)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make a simple function for getting the best configuration from a kernel tuner run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_config(objective: str, tune_parameters: dict, higher_is_better=True, strategy='genetic_algorithm', fevals=200) -> tuple[dict, list]:\n",
    "    res_opt, env_opt = kt.tune_kernel(\n",
    "        \"Xgemm\",\n",
    "        \"\",\n",
    "        problem_size,\n",
    "        [],\n",
    "        tune_parameters,\n",
    "        block_size_names=block_size_names.copy(),\n",
    "        simulation_mode=True,\n",
    "        restrictions=restrict,\n",
    "        grid_div_x=grid_div_x,\n",
    "        grid_div_y=grid_div_y,\n",
    "        strategy=strategy,\n",
    "        strategy_options=dict(max_fevals=fevals),\n",
    "        metrics=metrics,\n",
    "        objective=objective,\n",
    "        objective_higher_is_better=higher_is_better,\n",
    "        cache=\"GEMM_A100_cache.json\",\n",
    "        quiet=True\n",
    "    )\n",
    "    return env_opt['best_config'], res_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Time\n",
    "\n",
    "We start by simply optimizing for the lowest possible time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_race_to_idle, res_race_to_idle = get_optimal_config(\"time\", tune_params, higher_is_better=False)\n",
    "config_race_to_idle['name'] = \"race-to-idle (global)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Time and Energy\n",
    "\n",
    "The next step is to use our previous time-optimal configuration, and re-tune only the clock frequencies for energy efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dictionary of tunable parameters with only the clock frequencies \n",
    "tune_params_only_clocks = tune_params.copy()\n",
    "for key, value in config_race_to_idle.items():\n",
    "    if key != \"nvml_gr_clock\" and key in tune_params_only_clocks:\n",
    "        tune_params_only_clocks[key] = [value]\n",
    "\n",
    "# tune the clock frequencies for energy efficiency\n",
    "config_race_to_idle_plus_clocks, _ = get_optimal_config('GFLOPS/W', tune_params_only_clocks, strategy='brute_force')\n",
    "config_race_to_idle_plus_clocks['name'] = \"race-to-idle + clocks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Energy\n",
    "\n",
    "The final step is to tune for energy efficiency globally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_energy_to_solution, res_energy_to_solution = get_optimal_config(\"GFLOPS/W\", tune_params)\n",
    "config_energy_to_solution['name'] = \"energy-to-solution (global)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Results\n",
    "\n",
    "We can now look at the results in terms of energy efficiency per configuration in the bar chart below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([config_race_to_idle, config_race_to_idle_plus_clocks, config_energy_to_solution])\n",
    "sns.barplot(x=df.nvml_energy, y=df.name, orient='h', hue=df.name, legend=False)\n",
    "plt.xlabel('Energy (J), lower is better')\n",
    "plt.ylabel('')\n",
    "plt.title('Lowest energy configuration')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also make a scatterplot to show the relation between energy and time of our three configurations. \n",
    "In addition, we can see the difference in how Kernel Tuner optimizes for performance and energy efficiency, and how the optimization algorithm improves over time, by plotting the configurations explored during tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot our three configurations\n",
    "sns.scatterplot(x=df['GFLOPS/W'], y=df['GFLOP/s'], hue=df.name, s=250)\n",
    "\n",
    "# plot the configurations tried when optimizing for time\n",
    "df_time = pd.DataFrame(res_race_to_idle)\n",
    "sns.scatterplot(x=df_time['GFLOPS/W'], y=df_time['GFLOP/s'], hue=df_time.index, alpha=0.6, palette=sns.light_palette(\"midnightblue\", as_cmap=True), legend=False)\n",
    "\n",
    "# plot the configurations tried when optimizing for energy\n",
    "df_energy = pd.DataFrame(res_energy_to_solution)\n",
    "sns.scatterplot(x=df_energy['GFLOPS/W'], y=df_energy['GFLOP/s'], hue=df_energy.index, alpha=0.6, palette=sns.light_palette(\"forestgreen\", as_cmap=True), legend=False)\n",
    "\n",
    "# finishing touches to the plot\n",
    "plt.xlabel('GFLOPs per Watt, higher is better')\n",
    "plt.ylabel('GFLOPs per second, higher is better')\n",
    "plt.title('Energy versus Time')\n",
    "plt.legend(title='', loc=\"upper left\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerneltuner_bayesopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
