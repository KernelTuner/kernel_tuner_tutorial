{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmH1n4971xm0"
   },
   "source": [
    "# GPU Optimization with Kernel Tuner\n",
    "\n",
    "## First hands-on\n",
    "\n",
    "Welcome to the first hands-on of the GPU optimization with Kernel Tuner tutorial.\n",
    "\n",
    "The goal of this hands-on exercise is to familiarize with calling Kernel Tuner from Python to tune our first CUDA kernel for performance.\n",
    "\n",
    "We start by importing `numpy` and `kernel_tuner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "As8FyYq3EtoK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import kernel_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLe_BXzR5PTk"
   },
   "source": [
    "Before using Kernel Tuner, we will create a text file containing the code of the CUDA kernel that we are going to use in this hands-on.\n",
    "\n",
    "This simple kernel is called `vector_add` and computes the element-wise sum of two vectors of size `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgnQk_bmEx_F"
   },
   "outputs": [],
   "source": [
    "%%writefile vector_add_kernel.cu\n",
    "\n",
    "__global__ void vector_add(float * c, float * a, float * b, int n) {\n",
    "    int i = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
    "\n",
    "    if ( i < n ) {\n",
    "        c[i] = a[i] + b[i];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbkMDIgO7V9h"
   },
   "source": [
    "The execution of the cell above has created the file `vector_add_kernel.cu` containing the source code of our kernel.\n",
    "\n",
    "We can now use Kernel Tuner to execute the code on the GPU; please read carefully both code and comments below to become familiar with how Kernel Tuner works.\n",
    "\n",
    "For more details refer to the [API](https://KernelTuner.github.io/kernel_tuner/stable/user-api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZPTL1kjE-OS"
   },
   "outputs": [],
   "source": [
    "# the size of the vectors\n",
    "size = 1000000\n",
    "\n",
    "# all the kernel input and output data need to use numpy data types,\n",
    "# note that we explicitly state that these arrays should consist of\n",
    "# 32 bit floating-point values, to match our kernel source code\n",
    "a = np.random.randn(size).astype(np.float32)\n",
    "b = np.random.randn(size).astype(np.float32)\n",
    "c = np.zeros_like(b)\n",
    "n = np.int32(size)\n",
    "\n",
    "# now we combine these variables in an argument list, which matches\n",
    "# the order and types of the function arguments of our CUDA kernel\n",
    "args = [c, a, b, n]\n",
    "\n",
    "# the next step is to create a dictionary to tell Kernel Tuner about\n",
    "# the tunable parameters in our code and what values these may take\n",
    "tune_params = dict()\n",
    "# add some values to the block_size_x tunable parameter\n",
    "tune_params[\"block_size_x\"] = [1]\n",
    "\n",
    "\n",
    "# finally, we call tune_kernel to start the tuning process. To do so,\n",
    "# we pass\n",
    "#    the name of the kernel we'd like to tune, in our case: \"vector_add\",\n",
    "#    the name of the file containing our source code,\n",
    "#    the problem_size that our kernel operates on\n",
    "#    the argument list to call our kernel function\n",
    "#    the dictionary with tunable parameters\n",
    "results, env = kt.tune_kernel(\"vector_add\", \"vector_add_kernel.cu\", size, args, tune_params, lang=\"cupy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF1HCWx4Dzp8"
   },
   "source": [
    "What happens when you run the cell above is that Kernel Tuner compiles and benchmarks our vector_add kernel using different thread block dimensions. A summary of the results is printed to the console. The `tune_kernel` function also returns two outputs that we saved as `results` and `env`:\n",
    "\n",
    "* `results` is a list of dictionaries, each containing detailed information about the configurations that have been benchmarked;\n",
    "* `env` is a dictionary that stores information about the hardware and software environment in which this experiment took place; it is recommended to store this information along with the benchmark results.\n",
    "\n",
    "We can also print the content of `results` to have a look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHlbScKUGir3"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of configurations: {len(results)}\")\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbvRO_gzFOcU"
   },
   "source": [
    "As we can see the results returned by `tune_kernel` lists the average execution time of our kernel in the field \"time\" and even includes the individual measurements of each kernel that was benchmarked stored under \"times\".\n",
    "\n",
    "Kernel Tuner also collects a lot of other timing information, including the overall time it took to compile our kernel and benchmark our kernel.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "00-Kernel_Tuner-Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
