{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0oxTslc7KWc"
      },
      "source": [
        "# Kernel Tuner Tutorial\n",
        "\n",
        "## Getting Started Hands-on\n",
        "\n",
        "In this hands-on we will look at two features of Kernel Tuner that have been recently introduced to you: **tunable grid dimensions** and **user defined metrics**.\n",
        "\n",
        "But first, if you have not done it already, it is time to install and import kernel_tuner and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ieqcoy4_3BDX"
      },
      "outputs": [],
      "source": [
        "%pip install numpy\n",
        "%pip install pycuda\n",
        "%pip install kernel_tuner\n",
        "\n",
        "import numpy as np\n",
        "import kernel_tuner as kt\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd9z8p1VM4yG"
      },
      "source": [
        "To introduce these concepts we will use a modified vector add kernel.\n",
        "\n",
        "This kernel computes the same result as the kernel in the previous hands-on, i.e. the elementwise sum of two vectors of size `n`, but each thread can compute more than one element.\n",
        "\n",
        "The content of the cell is written to the `vector_add_tiled.cu` file, and you only need to execute this cell once as this hands-on does not require to change the implementation of the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJa6qNHOTnZK"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add_tiled.cu\n",
        "\n",
        "__global__ void vector_add(float * c, float * a, float * b, int n) {\n",
        "    int i = (blockIdx.x * blockDim.x * tiling_factor) + (threadIdx.x * tiling_factor);\n",
        "    \n",
        "    if ( (i + tiling_factor) <= n ) {\n",
        "        #pragma unroll\n",
        "        for ( int item = 0; item < tiling_factor; item++ ) {\n",
        "            c[i + item] = a[i + item] + b[i + item];\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANUVMtorYIad"
      },
      "source": [
        "Before running the code we need to allocate memory and add some tuning parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFB85iP0aUBx"
      },
      "outputs": [],
      "source": [
        "size = 1000000\n",
        "\n",
        "compiler_flags = [\"-Wno-deprecated-gpu-targets\"]\n",
        "\n",
        "a = np.random.randn(size).astype(np.float32)\n",
        "b = np.random.randn(size).astype(np.float32)\n",
        "c = np.zeros_like(b)\n",
        "n = np.int32(size)\n",
        "\n",
        "args = [c, a, b, n]\n",
        "\n",
        "tune_params = collections.OrderedDict()\n",
        "tune_params[\"block_size_x\"] = [2**i for i in range(0, 11)]\n",
        "tune_params[\"tiling_factor\"] = [i for i in range(1, 11)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9kh32ixcssa"
      },
      "source": [
        "Normally, Kernel Tuner does compute the CUDA grid size for you based on problem size and number of threads per block. However, this is not possible for cases like this one where other tunable parameters (i.e. `tiling_factor`) other than the number of threads can possibly affect the grid size.\n",
        "\n",
        "It is your responsibility to configure Kernel Tuner to work with **tunable grid dimensions**. To do so you can define a Python list containing a string that represent the right expression to use for computing the grid size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aQ0AqT7eEqI"
      },
      "outputs": [],
      "source": [
        "# define in the correct way how the problem size should be divided\n",
        "grid_div_x = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SziiWji4fJ5o"
      },
      "source": [
        "Execution time is important, but not always the most relevant metric for many users. Because of this, Kernel Tuner allows to work with **user defined metrics** that are computed within and then returned by `tune_kernel`.\n",
        "\n",
        "Metrics are passed to Kernel Tuner as `lambda` functions contained in a dictionary, with the key of the entry being the name of the metric itself.\n",
        "\n",
        "It is your responsibility to define one or more metrics and then tune the provided kernel. Possible user defined metrics in this case are the number of operations per second, or memory memory bandwidth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbJwYvWsffiI"
      },
      "outputs": [],
      "source": [
        "# define at least one user defined metric for the kernel\n",
        "metrics = collections.OrderedDict()\n",
        "metrics[] = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2JQBidxfftX"
      },
      "source": [
        "Do not forget to pass the additional parameters to the `tune_kernel` function as documented in Kernel Tuner's [API](https://benvanwerkhoven.github.io/kernel_tuner/user-api.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-bDAqozfscV"
      },
      "outputs": [],
      "source": [
        "# add the right parameters to the tune_kernel method\n",
        "results, env = kt.tune_kernel(\"vector_add\", \"vector_add_tiled.cu\",\n",
        "                             size, args, tune_params, compiler_options=compiler_flags)\n",
        "\n",
        "print(\"Number of configurations: {}\".format(len(results)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "01-Kernel_Tuner-Getting_Stared.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
