{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kernel_Tuner-Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mou9PuILWPwb"
      },
      "source": [
        "# Kernel Tuner Tutorial\n",
        "\n",
        "## Convolution\n",
        "\n",
        "In this hands-on we are going to play with all the features of Kernel Tuner.\n",
        "\n",
        "We start by providing the source code of a convolution algorithm; your goal is to tune this kernel, without modifying the CUDA code.\n",
        "\n",
        "This particular convolution applies a random `17x17` filter to a `512x512` image, and it has multiple tunable parameters:\n",
        "\n",
        "* `block_size_x`: the number of threads per block in the `x` dimension\n",
        "* `block_size_y`: the number of threads per block in the `y` dimension\n",
        "* `tile_size_x`: the size of the tile in the `x` dimension\n",
        "* `tile_size_y`: the size of the tile in the `y` dimension\n",
        "* `use_padding`: a binary flag to disable or enable padding in shared memory\n",
        "* `read_only`: a binary flag to disable or enable the use of read-only cache\n",
        "\n",
        "After each section in the tutorial, and after you are done with the corresponing hands-on, you can get back to this notebook and improve the tuning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8GnQhsdlvjz"
      },
      "source": [
        "%%writefile convolution.cu\n",
        "\n",
        "#define image_height 512\n",
        "#define image_width 512\n",
        "\n",
        "#define filter_height 17\n",
        "#define filter_width 17\n",
        "\n",
        "#define border_height ((filter_height/2)*2)\n",
        "#define border_width ((filter_width/2)*2)\n",
        "#define input_height (image_height + border_height)\n",
        "#define input_width (image_width + border_width)\n",
        "\n",
        "#ifndef block_size_x\n",
        "    #define block_size_x 16\n",
        "#endif\n",
        "#ifndef block_size_y\n",
        "    #define block_size_y 16\n",
        "#endif\n",
        "#ifndef block_size_z\n",
        "    #define block_size_z 1\n",
        "#endif\n",
        "#ifndef tile_size_x\n",
        "    #define tile_size_x 1\n",
        "#endif\n",
        "#ifndef tile_size_y\n",
        "    #define tile_size_y 1\n",
        "#endif\n",
        "\n",
        "#define i_end min(block_size_y*tile_size_y+border_height, input_height)\n",
        "#define j_end min(block_size_x*tile_size_x+border_width, input_width)\n",
        "\n",
        "/*\n",
        " * If requested, we can use the __ldg directive to load data through the\n",
        " * read-only cache. \n",
        " */\n",
        "#define USE_READ_ONLY_CACHE read_only\n",
        "#if USE_READ_ONLY_CACHE == 1\n",
        "#define LDG(x, y) __ldg(x+y)\n",
        "#elif USE_READ_ONLY_CACHE == 0\n",
        "#define LDG(x, y) x[y]\n",
        "#endif\n",
        "\n",
        "__constant__ float d_filter[17*17];\n",
        "\n",
        "/*\n",
        " * If use_padding == 1, we introduce (only when necessary) a number of padding\n",
        " * columns in shared memory to avoid shared memory bank conflicts\n",
        " *\n",
        " * padding columns are only inserted when block_size_x is not a multiple of 32 (the assumed number of memory banks)\n",
        " * and when the width of the data needed is not a multiple of 32. The latter is because some filter_widths never\n",
        " * cause bank conflicts.\n",
        " * \n",
        " * If not passed as a tunable parameter, padding is on by default\n",
        " */\n",
        "#define shared_mem_width (block_size_x*tile_size_x+border_width)\n",
        "#ifndef use_padding\n",
        "    #define use_padding 1\n",
        "#endif\n",
        "#if use_padding == 1\n",
        "    #if (((block_size_x % 32)!=0) && (((shared_mem_width-block_size_x)%32) != 0))\n",
        "        // next line uses &31 instead of %32, because % in C is remainder not modulo\n",
        "        #define padding_columns ((32 - (border_width + block_size_x*tile_size_x - block_size_x)) & 31)\n",
        "        #undef shared_mem_width\n",
        "        #define shared_mem_width (block_size_x*tile_size_x+border_width+padding_columns)\n",
        "    #endif\n",
        "#endif\n",
        "\n",
        "\n",
        "__global__ void convolution_kernel(float *output, float *input, float *filter) {\n",
        "    int ty = threadIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int by = blockIdx.y * block_size_y * tile_size_y;\n",
        "    int bx = blockIdx.x * block_size_x * tile_size_x;\n",
        "\n",
        "    // shared memory to hold all input data need by this thread block\n",
        "    __shared__ float sh_input[block_size_y*tile_size_y+border_height][shared_mem_width];\n",
        "\n",
        "    // load all input data needed by this thread block into shared memory\n",
        "    #pragma unroll\n",
        "    for (int i=ty; i<i_end; i+=block_size_y) {\n",
        "        #pragma unroll\n",
        "        for (int j=tx; j<j_end; j+=block_size_x) {\n",
        "            #if ((image_height%(block_size_y*tile_size_y)!=0) || (image_width%(block_size_x*tile_size_x)!=0))\n",
        "            int y = by+i;\n",
        "            int x = bx+j;\n",
        "            if (y < input_height && x < input_width) {\n",
        "                sh_input[i][j] = LDG(input, y*input_width+x);\n",
        "            }\n",
        "            #else\n",
        "                sh_input[i][j] = LDG(input, (by+i)*input_width + (bx+j));\n",
        "            #endif\n",
        "        }\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // thread-local registers to hold local sums\n",
        "    float sum[tile_size_y][tile_size_x];\n",
        "    #pragma unroll\n",
        "    for (int yi=0; yi<tile_size_y; yi++) {\n",
        "        #pragma unroll\n",
        "        for (int xi=0; xi<tile_size_x; xi++) {\n",
        "             sum[yi][xi] = 0.0f;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // for each filter weight\n",
        "    #pragma unroll\n",
        "    for (int i=0; i < filter_height; i++) {\n",
        "        #pragma unroll\n",
        "        for (int j=0; j < filter_width; j++) {\n",
        "\n",
        "            #pragma unroll\n",
        "            for (int yi=0; yi<tile_size_y; yi++) {   \n",
        "                #pragma unroll\n",
        "                for (int xi=0; xi<tile_size_x; xi++) {\n",
        "                    sum[yi][xi] += sh_input[ty+yi*block_size_y+i][tx+xi*block_size_x+j] * d_filter[i*filter_width+j];\n",
        "                }\n",
        "            }\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // store results to global memory\n",
        "    #pragma unroll\n",
        "    for (int yi=0; yi<tile_size_y; yi++) {   \n",
        "        #pragma unroll\n",
        "        for (int xi=0; xi<tile_size_x; xi++) {\n",
        "            #if ((image_height%(block_size_y*tile_size_y)!=0) || (image_width%(block_size_x*tile_size_x)!=0))\n",
        "            int y = by+ty+yi*block_size_y;\n",
        "            int x = bx+tx+xi*block_size_x;\n",
        "            if (y < image_height && x < image_width) {\n",
        "                output[y * image_width + x] = sum[yi][xi];\n",
        "            }\n",
        "            #else\n",
        "                output[(by+ty+yi*block_size_y) * image_width + bx+tx+xi*block_size_x] = sum[yi][xi];\n",
        "            #endif\n",
        "        }\n",
        "    }\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-v8n-XpaR__"
      },
      "source": [
        "Before using Kernel Tuner it is time to install and import it and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPkrdGA3aRk5"
      },
      "source": [
        "%pip install numpy\n",
        "%pip install pycuda\n",
        "%pip install kernel_tuner\n",
        "\n",
        "import numpy as np\n",
        "import kernel_tuner as kt\n",
        "import collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68enL_rJeoop"
      },
      "source": [
        "It is now up to you to use Kernel Tuner to find the best performing configuration of the convolution kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHDg6vr8e8Ms"
      },
      "source": [
        "# problem sizes\n",
        "problem_size = (512, 512)\n",
        "size = np.prod(problem_size)\n",
        "filter_size = 17\n",
        "input_size = ((problem_size[0] + filter_size - 1) * (problem_size[1] + filter_size - 1))\n",
        "\n",
        "# memory allocation\n",
        "output_image = np.zeros(size).astype(np.float32)\n",
        "input_image = np.random.randn(input_size).astype(np.float32)\n",
        "filter_weights = np.random.randn(filter_size * filter_size).astype(np.float32)\n",
        "cmem_args = {'d_filter': filter_weights}\n",
        "args = [output_image, input_image, filter_weights]\n",
        "\n",
        "# tuning parameters\n",
        "compiler_flags = [\"-Wno-deprecated-gpu-targets\"]\n",
        "tune_params = collections.OrderedDict()\n",
        "\n",
        "# tuning\n",
        "results, env = kt.tune_kernel(\"convolution_kernel\", \"convolution.cu\",\n",
        "        problem_size, args, tune_params,\n",
        "        cmem_args=cmem_args, compiler_options=compiler_flags,\n",
        "        verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
